{
    "dataset": "leverco",
    "run": "be0782ee-6b3a-45d5-a155-dc2c2dfb04bf",
    "source": "",
    "snippets_used": 2,
    "attempts": 7,
    "final_scraper_code": "# imports\nimport requests\nfrom bs4 import BeautifulSoup\nimport json\n\ndef scraper(url: str) -> str:\n  # send GET request to the URL\n  response = requests.get(url)\n\n  # create BeautifulSoup object for parsing\n  soup = BeautifulSoup(response.text, 'html.parser')\n\n  # initialize empty list for job listings\n  job_listings = []\n\n  # scrape all job listings on the page\n  listings = soup.find_all('div', class_='posting')\n\n  # loop through each job listing and extract title, tag, and apply_link\n  for listing in listings:\n    # extract title\n    title = None\n    if listing.find('h5', class_='posting-title'):\n        title = listing.find('h5', class_='posting-title').text.strip()\n\n    # extract tag\n    tag = None\n    if listing.find('span', class_='sort-by-tag-wrapper'):\n        tag = listing.find('span', class_='sort-by-tag-wrapper').text.strip()\n\n    # extract apply_link\n    apply_link = None\n    if listing.find('a', class_='posting-btn-submit'):\n        apply_link = listing.find('a', class_='posting-btn-submit')['href']\n\n    # append data to job listings list\n    job_listings.append({\n        'title': title,\n        'tag': tag,\n        'apply_link': apply_link\n    })\n\n  # print job listings as JSON\n  print(json.dumps(job_listings, indent=2))\n\nif __name__ == '__main__':\n  url = \"https://jobs.lever.co/appboxo\"\n  scraper(url)",
    "test_count": 4,
    "test_succ_count": 0
}