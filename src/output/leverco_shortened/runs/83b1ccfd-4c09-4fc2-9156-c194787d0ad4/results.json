{
    "dataset": "leverco_shortened",
    "run": "83b1ccfd-4c09-4fc2-9156-c194787d0ad4",
    "source": "",
    "snippets_used": 1,
    "attempts": 2,
    "final_scraper_code": "# imports\nimport requests\nimport bs4 \nimport json\n\ndef scraper(url: str) -> str:\n    \"\"\"\n    Scrapes job listings from the given URL and prints out the title, tag, and apply_link for each job listing as JSON.\n    \"\"\"\n    # send get request to the URL\n    response = requests.get(url)\n    # convert response content into BeautifulSoup object\n    soup = bs4.BeautifulSoup(response.content, 'html.parser')\n    # find all job listings on the page\n    listings = soup.find_all('div', {'class': 'posting'})\n    # initialize empty list to store job listings data\n    job_listings = []\n    for listing in listings:\n        # extract title\n        title = listing.find('h5', {'data-qa': 'posting-name'}).text\n        # extract tag\n        tag = listing.find('span', {'class': 'sort-by-location'}).text\n        # extract apply link\n        apply_link = listing.find('a', {'class': 'posting-btn-submit'})['href']\n        # add job listing data to the list\n        job_listings.append({\n            \"title\": title,\n            \"tag\": tag,\n            \"apply_link\": apply_link\n        })\n    \n    # print job listings as JSON\n    print(json.dumps(job_listings, indent=4, sort_keys=True))\n\nif __name__ == '__main__':\n    url = \"https://jobs.lever.co/appboxo\"\n    scraper(url)",
    "test_count": 8,
    "test_succ_count": 5
}