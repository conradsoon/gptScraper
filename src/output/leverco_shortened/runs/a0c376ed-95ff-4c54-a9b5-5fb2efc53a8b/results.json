{
    "dataset": "leverco_shortened",
    "run": "a0c376ed-95ff-4c54-a9b5-5fb2efc53a8b",
    "source": "",
    "snippets_used": 3,
    "attempts": 8,
    "final_scraper_code": "# imports\nimport bs4 \nimport requests\nimport json\n\ndef scraper(url: str) -> str:\n  # get webpage content\n  page = requests.get(url)\n\n  # create BeautifulSoup object\n  soup = BeautifulSoup(page.content, 'html.parser')\n\n  # find all job listings\n  listings = soup.find_all('div', class_=\"posting\")\n\n  # initialize empty list to store data\n  data = []\n\n  # loop through job listings\n  for listing in listings:\n    # check if listing is not None\n    if listing is not None:\n      # extract title, tag and apply link from the listing\n      title_tag = listing.find('h5', class_=\"posting-name\")\n      # check if title_tag is not None\n      if title_tag is not None:\n        title = title_tag.text.strip()\n        tag = listing.find('span', class_=\"sort-by-commitment\").text.strip()\n        apply_link = listing.find('a', class_=\"posting-btn-submit\").get('href')\n\n        # store data in a dictionary\n        entry = {\n          'title': title,\n          'tag': tag,\n          'apply_link': apply_link,\n        }\n\n        # append dictionary to data list\n        data.append(entry)\n\n  # check if data list is not empty\n  if len(data) > 0:\n    # print data in JSON format\n    print(json.dumps(data, indent=4))\n  else:\n    print(\"No data was found.\")\n\nif __name__ == '__main__':\n  url = \"https://jobs.lever.co/appboxo\"\n  scraper(url)",
    "test_count": 8,
    "test_succ_count": 1
}