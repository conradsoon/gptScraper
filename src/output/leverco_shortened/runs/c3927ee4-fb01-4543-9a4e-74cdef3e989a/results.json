{
    "dataset": "leverco_shortened",
    "run": "c3927ee4-fb01-4543-9a4e-74cdef3e989a",
    "source": "",
    "snippets_used": 3,
    "attempts": 2,
    "final_scraper_code": "# imports\nimport requests\nfrom bs4 import BeautifulSoup\nimport json\n\ndef scraper(url: str) -> None:\n  # send request to url\n  response = requests.get(url)\n  # parse HTML with BeautifulSoup\n  soup = BeautifulSoup(response.content, 'html.parser')\n  # find all postings on the webpage\n  postings = soup.find_all(class_='posting')\n  # create empty list for storing job listings\n  job_listings = []\n  # loop through each posting\n  for posting in postings:\n    # extract job title\n    job_title = posting.find(class_='posting-title').find('h5').text.strip()\n    # check if job tag exists\n    if posting.find(class_='small-category-label workplaceTypes') is not None:\n      # extract job tag\n      job_tag = posting.find(class_='small-category-label workplaceTypes').text.strip()\n    else:\n      # assign None to job tag if it doesn't exist\n      job_tag = None\n    # extract apply link\n    apply_link = posting.find(class_='posting-apply').find('a')['href']\n    # create dictionary for job listing\n    job_dict = {'title': job_title, 'tag': job_tag, 'apply_link': apply_link}\n    # append dictionary to list\n    job_listings.append(job_dict)\n  # print out job listings as JSON\n  print(json.dumps(job_listings, indent=2))\n\nif __name__ == '__main__':\n  url = \"https://jobs.lever.co/appboxo\"\n  scraper(url)",
    "test_count": 8,
    "test_succ_count": 6
}