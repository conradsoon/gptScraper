{
    "dataset": "../output/arxiv_data",
    "run": "0a8fd278-5d75-426b-a580-fbfc557623a6",
    "source": "",
    "snippets_used": 2,
    "attempts": 3,
    "snippets_tried": [
        "nt=\"2311.01449\" name=\"citation_arxiv_id\"/><meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal semantic control over topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining. TopicGPT can be further extended to hierarchical topical modeling, enabling users to explore topics at various levels of granularity. By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.' name=\"citation_abstract\"/>\n</link></meta></meta></meta></link></link></link></link></head>\n<body class=\"with-cu-identity\">\n<div class=\"flex-wrap-footer\">\n<header>\n<a class=\"is-sr-only\" href=\"#content\">Skip to main content</a>\n<!-- start desktop header -->\n<div class=\"columns is-vcentered is-hidden-mobile\" id=\"cu-identity\">\n<div class=\"column\" id=\"cu-logo\">\n<a href=\"https://www.cornell.edu/\"><img alt=\"Cornell University\" src=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\"/></a>\n</div><div class=\"column\" id=\"support-ack\">\n<span id=\"support-ack-url\">We gratefully acknowledge support from the Simons Foundation, <a href=\"",
        "ramework that uses large language models (LLMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining. TopicGPT can be further extended to hierarchical topical modeling, enabling users to explore topics at various levels of granularity. By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.\n    </blockquote>\n<!--CONTEXT-->\n<div class=\"metatable\">\n<table summary=\"Additional metadata\"><tr>\n<td class=\"tablecell label\">Subjects:</td>\n<td class=\"tablecell subjects\">\n<span class=\"primary-subject\">Computation and Language (cs.CL)</span></td>\n</tr><tr>\n<td class=\"tablecell label\">Cite as:</td>\n<td class=\"tablecell arxivid\"><span class=\"arxivid\"><a href=\"https://arxiv.org/abs/2311.01449\">arXiv:2311.01449</a> [cs.CL]</span></td>\n</tr>\n<tr>\n<td class=\"tablecell label\">\u00a0</td>\n<td class=\"tablecell arxividv\">(or <span class=\"arxivid\">\n<a href=\"https://arxiv.org/abs/2311.01449v1\">arXiv:2311.01449v1</a> [cs.CL]</span> for this version)\n          </td>\n</tr> <tr>\n<td class=\"tablecell label\">\u00a0</td>\n<td class=\"tablecell arxivdoi\">\n<a href=\"https://doi.org/10.48550/arXiv.2311.01449\">https://doi.org/10.48550/arXiv.2311.01449</a>\n<div class=\"button-and-tooltip\">\n<button aria-describedby=\"more-info-desc-1\" class=\"more-info\">\n<svg height=\"15\" role=\"presentation\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"\" d=\"M256 8C119.043 8 8 119.0",
        "LMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining. TopicGPT can be further extended to hierarchical topical modeling, enabling users to explore topics at various levels of granularity. By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.' property=\"og:description\"/>\n<meta content=\"@arxiv\" name=\"twitter:site\"/>\n<meta content=\"summary\" name=\"twitter:card\"/>\n<meta content=\"TopicGPT: A Prompt-based Topic Modeling Framework\" name=\"twitter:title\"/>\n<meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to...' name=\"twitter:description\"/>\n<meta content=\"https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png\" name=\"twitter:image\"/>\n<meta content=\"arXiv logo\" name=\"twitter:image:alt\"/>\n<link href=\"https://static.arxiv.org/static/browse/0.3.4/css/tooltip.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"><link href=\"https://static.arxiv.org/js/bibex-dev/bibex.css?20200709\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>  \n\n\n\n<meta content=\"TopicGPT: A Prompt-based Topic Modeling Framework\" name=\"citation_title\"/><meta content=\"Pham, Chau Minh\" name=\"citation_author\"/><meta content=\"Hoyle, Alexander\" name=\"citation_author\"/><meta content=\"Sun, Simeng\" name=\"citation_auth",
        ".com\" target=\"_blank\">What is CatalyzeX?</a>)</em>\n</div>\n</div>\n<div class=\"columns is-mobile lab-row\">\n<div class=\"column lab-switch\">\n<label class=\"switch\">\n<input aria-labelledby=\"label-for-dagshub\" class=\"lab-toggle\" data-script-url=\"https://static.arxiv.org/static/browse/0.3.4/js/dagshub.js\" id=\"dagshub-toggle\" type=\"checkbox\"/>\n<span class=\"slider\"></span>\n<span class=\"is-sr-only\">DagsHub Toggle</span>\n</label>\n</div>\n<div class=\"column lab-name\">\n<span id=\"label-for-dagshub\">DagsHub</span> <em>(<a href=\"https://dagshub.com/\" target=\"_blank\">What is DagsHub?</a>)</em>\n</div>\n</div>\n<div class=\"columns is-mobile lab-row\">\n<div class=\"column lab-switch\">\n<label class=\"switch\">\n<input aria-labelledby=\"label-for-pwc\" class=\"lab-toggle\" data-script-url=\"https://static.arxiv.org/static/browse/0.3.4/js/paperswithcode.js\" id=\"paperwithcode-toggle\" type=\"checkbox\"/>\n<span class=\"slider\"></span>\n<span class=\"is-sr-only\">Links to Code Toggle</span>\n</label>\n</div>\n<div class=\"column lab-name\">\n<span id=\"label-for-pwc\">Papers with Code</span> <em>(<a href=\"https://paperswithcode.com/\" target=\"_blank\">What is Papers with Code?</a>)</em>\n</div>\n</div>\n<div class=\"columns is-mobile lab-row\">\n<div class=\"column lab-switch\">\n<label class=\"switch\">\n<input aria-labelledby=\"label-for-sciencecast\" class=\"lab-toggle\" data-script-url=\"https://static.arxiv.org/static/browse/0.3.4/js/sciencecast.js\" id=\"sciencecast-toggle\" type=\"checkbox\"/>\n<span class=\"slider\"></span>\n<span class=\"is-sr-only\">ScienceCast Toggle</span>\n</label>\n</div>\n<div class=\"column lab-name\">\n<span id=\"label-for-sciencecast\">ScienceCast</span> <em>(<a href=\"https://sciencecast.org/welcome\" target=\"_blank\">What is ScienceCast?</a>)</em>\n</div>\n</div>\n</div>\n<div id=\"catalyzex-output\" style=\"display:none\"></div>\n<div id=\"dagshub-output\" style=\"display:none\"></div>\n<div id=\"pwc-output\" style=\"display:none\"></div>\n<div id=\"pwc-data-output\" style=\"display:none\"></div>\n<div id=\"sciencecast-output\" style=\"display:none\"",
        "m-504 45h-27v-27h27zm27-27h-27v27h27zm54-27h-27v27h27zm0 27h-27v27h27zm27 0h-27v27h27zm0 27h-27v27h27zm27 0h-27v27h27zm0 27h-27v27h27zm-81-108h-27v27h27z\" fill=\"#ccc\"></path><path d=\"M598.6 665.1H41.5C-76.5 667 176 280.2 176 280.2h53a46.5 46.5 0 0162.8-56.3 29.2 29.2 0 1128.5 35.9h-1a46.5 46.5 0 01-1.5 20.3l142.5-.1s255.3 387 138.3 385.1zM291 181a29.3 29.3 0 10-29.2-29.3A29.3 29.3 0 00291 181zm65.4-66.8a22.4 22.4 0 10-22.5-22.4 22.4 22.4 0 0022.5 22.4z\" fill=\"#fc0\"></path><path d=\"M245.5 172V10h153v162s324 495 198 495h-558c-126 0 207-495 207-495zm126 54h56m-13 72h56m-9 72h56m-20 72h56m-22 72h56m-29 72h56m-457-45c20.8 41.7 87.3 81 160.7 81 72.1 0 142.1-38.2 163.4-81\" fill=\"none\" stroke=\"#000\" stroke-miterlimit=\"10\" stroke-width=\"20\"></path><path d=\"M273.3 421.7c0 31-9.8 56.3-21.9 56.3s-21.8-25.2-21.8-56.3 9.8-56.3 21.8-56.3 21.9 25.2 21.9 56.3zm114.4-56.3c-12 0-21.8 25.2-21.8 56.3s9.7 56.3 21.8 56.3 21.9-25.2 21.9-56.3-9.8-56.3-21.9-56.3zM150.1 526.6c-18.2 6.7-27.5 22.9-23.2 30.2s14.8-5.5 33-12.2 37.4-4.9 33-12.2-24.5-12.6-42.8-5.8zm296 5.8c-4.2 7.3 14.9 5.5 33.1 12.2s28.7 19.5 33 12.2-5-23.5-23.2-30.2-38.5-1.5-42.8 5.8z\"></path></svg></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<!-- END LABS AREA -->\n<div class=\"endorsers\">\n<a class=\"endorser-who\" href=\"/auth/show-endorsers/2311.01449\">Which authors of this paper are endorsers?</a> |\n    <a href=\"javascript:setMathjaxCookie()\" id=\"mathjax_toggle\">Disable MathJax</a> (<a href=\"https://info.arxiv.org/help/mathjax.html\">What is MathJax?</a>)\n    <span class=\"help\" style=\"font-style: normal; float: right; margin-top: 0; margin-right: 1em;\"></span>\n</div>\n\n</div>\n</div>\n</main>\n<footer style=\"clear: both;\">\n<div aria-label=\"Secondary\" class=\"columns is-desktop\" role=\"navigation\" style=\"margin: -0.75em -0.75em 0.75em -0.75em\">\n<!-- Macro-Column 1 -->\n<div class=\"column\" style=\"padding: 0;\">\n<div class=\"columns\">\n<div class=\"column\">\n<ul style=\"list-style: none; line-height: 2;\">\n<li><a href=\"https://info.arxiv.org/about\">About",
        "\n<div id=\"spaces-output\"></div>\n</div>\n<input id=\"tabfour\" name=\"tabs\" type=\"radio\"/>\n<label for=\"tabfour\">Related Papers</label>\n<div class=\"tab\">\n<h1>Recommenders and Search Tools</h1>\n<div class=\"toggle\">\n<div class=\"columns is-mobile lab-row\">\n<div class=\"column lab-switch\">\n<label class=\"switch\">\n<input aria-labelledby=\"label-for-influenceflower\" class=\"lab-toggle\" data-script-url=\"https://static.arxiv.org/static/browse/0.3.4/js/influenceflower.js\" id=\"influenceflower-toggle\" type=\"checkbox\"/>\n<span class=\"slider\"></span>\n<span class=\"is-sr-only\">Link to Influence Flower</span>\n</label>\n</div>\n<div class=\"column lab-name\">\n<span id=\"label-for-influenceflower\">Influence Flower</span> <em>(<a href=\"https://influencemap.cmlab.dev/\" target=\"_blank\">What are Influence Flowers?</a>)</em>\n</div>\n</div>\n<div class=\"columns is-mobile lab-row\">\n<div class=\"column lab-switch\">\n<label class=\"switch\">\n<input aria-labelledby=\"label-for-connected-papers\" class=\"lab-toggle\" data-script-url=\"https://static.arxiv.org/static/browse/0.3.4/js/connectedpapers.js\" id=\"connectedpapers-toggle\" type=\"checkbox\"/>\n<span class=\"slider\"></span>\n<span class=\"is-sr-only\">Connected Papers Toggle</span>\n</label>\n</div>\n<div class=\"column lab-name\">\n<span id=\"label-for-connected-papers\">Connected Papers</span> <em>(<a href=\"https://www.connectedpapers.com/about\" target=\"_blank\">What is Connected Papers?</a>)</em>\n</div>\n</div>\n<div class=\"columns is-mobile lab-row\">\n<div class=\"column lab-switch\">\n<label class=\"switch\">\n<input aria-labelledby=\"label-for-core\" class=\"lab-toggle\" id=\"core-recommender-toggle\" type=\"checkbox\"/>\n<span class=\"slider\"></span>\n<span class=\"is-sr-only\">Core recommender toggle</span>\n</label>\n</div>\n<div class=\"column lab-name\">\n<span id=\"label-for-core\">CORE Recommender</span> <em>(<a href=\"https://core.ac.uk/services/recommender\">What is CORE?</a>)</em>\n</div>\n</div></div>\n<div id=\"influenceflower-output\"></div>\n<div id=\"influenceflower-output-graph\" style=\"display:none",
        " streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.' property=\"og:description\"/>\n<meta content=\"@arxiv\" name=\"twitter:site\"/>\n<meta content=\"summary\" name=\"twitter:card\"/>\n<meta content=\"TopicGPT: A Prompt-based Topic Modeling Framework\" name=\"twitter:title\"/>\n<meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to...' name=\"twitter:description\"/>\n<meta content=\"https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png\" name=\"twitter:image\"/>\n<meta content=\"arXiv logo\" name=\"twitter:image:alt\"/>\n<link href=\"https://static.arxiv.org/static/browse/0.3.4/css/tooltip.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"><link href=\"https://static.arxiv.org/js/bibex-dev/bibex.css?20200709\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>  \n\n\n\n<meta content=\"TopicGPT: A Prompt-based Topic Modeling Framework\" name=\"citation_title\"/><meta content=\"Pham, Chau Minh\" name=\"citation_author\"/><meta content=\"Hoyle, Alexander\" name=\"citation_author\"/><meta content=\"Sun, Simeng\" name=\"citation_author\"/><meta content=\"Iyyer, Mohit\" name=\"citation_author\"/><meta content=\"2023/11/02\" name=\"citation_date\"/><meta content=\"2023/11/02\" name=\"citation_online_date\"/><meta content=\"https://arxiv.org/pdf/2311.01449.pdf\" name=\"citation_pdf_url\"/><meta content=\"2311.01449\" name=\"citation_arxiv_id\"/><meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal semantic control over topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collectio",
        " with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining. TopicGPT can be further extended to hierarchical topical modeling, enabling users to explore topics at various levels of granularity. By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.\n    </blockquote>\n<!--CONTEXT-->\n<div class=\"metatable\">\n<table summary=\"Additional metadata\"><tr>\n<td class=\"tablecell label\">Subjects:</td>\n<td class=\"tablecell subjects\">\n<span class=\"primary-subject\">Computation and Language (cs.CL)</span></td>\n</tr><tr>\n<td class=\"tablecell label\">Cite as:</td>\n<td class=\"tablecell arxivid\"><span class=\"arxivid\"><a href=\"https://arxiv.org/abs/2311.01449\">arXiv:2311.01449</a> [cs.CL]</span></td>\n</tr>\n<tr>\n<td class=\"tablecell label\">\u00a0</td>\n<td class=\"tablecell arxividv\">(or <span class=\"arxivid\">\n<a href=\"https://arxiv.org/abs/2311.01449v1\">arXiv:2311.01449v1</a> [cs.CL]</span> for this version)\n          </td>\n</tr> <tr>\n<td class=\"tablecell label\">\u00a0</td>\n<td class=\"tablecell arxivdoi\">\n<a href=\"https://doi.org/10.48550/arXiv.2311.01449\">https://doi.org/10.48550/arXiv.2311.01449</a>\n<div class=\"button-and-tooltip\">\n<button aria-describedby=\"more-info-desc-1\" class=\"more-info\">\n<svg height=\"15\" role=\"presentation\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"\" d=\"M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-4",
        "27v-27zm27 0v27h27v-27zm0-27v27h27v-27zm27 0v27h27v-27zm-108 81v27h27v-27zm558 54v27h-27v-27zm-27-27v27h27v-27zm27-54v27h27v-27zm-27 0v27h27v-27zm0-27v27h27v-27zm-27 0v27h27v-27zm0-27v27h27v-27zm-27 0v27h27v-27zm108 81v27h27v-27zm0-495h27v27h-27zm-27 27h27v-27h-27zm-54-27h27v-27h-27zm0 27h27v-27h-27zm-27 0h27v-27h-27zm0 27h27v-27h-27zm-27 0h27v-27h-27zm0 27h27v-27h-27zm81-108h27v-27h-27zm-504 45h-27v-27h27zm27-27h-27v27h27zm54-27h-27v27h27zm0 27h-27v27h27zm27 0h-27v27h27zm0 27h-27v27h27zm27 0h-27v27h27zm0 27h-27v27h27zm-81-108h-27v27h27z\" fill=\"#ccc\"></path><path d=\"M598.6 665.1H41.5C-76.5 667 176 280.2 176 280.2h53a46.5 46.5 0 0162.8-56.3 29.2 29.2 0 1128.5 35.9h-1a46.5 46.5 0 01-1.5 20.3l142.5-.1s255.3 387 138.3 385.1zM291 181a29.3 29.3 0 10-29.2-29.3A29.3 29.3 0 00291 181zm65.4-66.8a22.4 22.4 0 10-22.5-22.4 22.4 22.4 0 0022.5 22.4z\" fill=\"#fc0\"></path><path d=\"M245.5 172V10h153v162s324 495 198 495h-558c-126 0 207-495 207-495zm126 54h56m-13 72h56m-9 72h56m-20 72h56m-22 72h56m-29 72h56m-457-45c20.8 41.7 87.3 81 160.7 81 72.1 0 142.1-38.2 163.4-81\" fill=\"none\" stroke=\"#000\" stroke-miterlimit=\"10\" stroke-width=\"20\"></path><path d=\"M273.3 421.7c0 31-9.8 56.3-21.9 56.3s-21.8-25.2-21.8-56.3 9.8-56.3 21.8-56.3 21.9 25.2 21.9 56.3zm114.4-56.3c-12 0-21.8 25.2-21.8 56.3s9.7 56.3 21.8 56.3 21.9-25.2 21.9-56.3-9.8-56.3-21.9-56.3zM150.1 526.6c-18.2 6.7-27.5 22.9-23.2 30.2s14.8-5.5 33-12.2 37.4-4.9 33-12.2-24.5-12.6-42.8-5.8zm296 5.8c-4.2 7.3 14.9 5.5 33.1 12.2s28.7 19.5 33 12.2-5-23.5-23.2-30.2-38.5-1.5-42.8 5.8z\"></path></svg></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<!-- END LABS AREA -->\n<div class=\"endorsers\">\n<a class=\"endorser-who\" href=\"/auth/show-endorsers/2311.01449\">Which authors of this paper are endorsers?</a> |\n    <a href=\"javascript:setMathjaxCookie()\" id=\"mathjax_toggle\">Disable MathJax</a> (<a href=\"https://info.arxiv.org/help/mathjax.html\">What is MathJax?</a>)\n    <span class=\"help\" style=\"font-style: normal; float: right; margin-top: 0; margin-right: 1em;\"></",
        "/label>\n</div>\n<div class=\"column lab-name\">\n<span id=\"label-for-replicate\">Replicate</span> <em>(<a href=\"https://replicate.com/docs/arxiv/about\" target=\"_blank\">What is Replicate?</a>)</em>\n</div>\n</div>\n<div class=\"columns is-mobile lab-row\">\n<div class=\"column lab-switch\">\n<label class=\"switch\">\n<input aria-labelledby=\"label-for-spaces\" class=\"lab-toggle\" data-script-url=\"https://static.arxiv.org/static/browse/0.3.4/js/spaces.js\" id=\"spaces-toggle\" type=\"checkbox\"/>\n<span class=\"slider\"></span>\n<span class=\"is-sr-only\">Spaces Toggle</span>\n</label>\n</div>\n<div class=\"column lab-name\">\n<span id=\"label-for-spaces\">Hugging Face Spaces</span> <em>(<a href=\"https://huggingface.co/docs/hub/spaces\" target=\"_blank\">What is Spaces?</a>)</em>\n</div>\n</div>\n</div>\n<div id=\"replicate-output\"></div>\n<div id=\"spaces-output\"></div>\n</div>\n<input id=\"tabfour\" name=\"tabs\" type=\"radio\"/>\n<label for=\"tabfour\">Related Papers</label>\n<div class=\"tab\">\n<h1>Recommenders and Search Tools</h1>\n<div class=\"toggle\">\n<div class=\"columns is-mobile lab-row\">\n<div class=\"column lab-switch\">\n<label class=\"switch\">\n<input aria-labelledby=\"label-for-influenceflower\" class=\"lab-toggle\" data-script-url=\"https://static.arxiv.org/static/browse/0.3.4/js/influenceflower.js\" id=\"influenceflower-toggle\" type=\"checkbox\"/>\n<span class=\"slider\"></span>\n<span class=\"is-sr-only\">Link to Influence Flower</span>\n</label>\n</div>\n<div class=\"column lab-name\">\n<span id=\"label-for-influenceflower\">Influence Flower</span> <em>(<a href=\"https://influencemap.cmlab.dev/\" target=\"_blank\">What are Influence Flowers?</a>)</em>\n</div>\n</div>\n<div class=\"columns is-mobile lab-row\">\n<div class=\"column lab-switch\">\n<label class=\"switch\">\n<input aria-labelledby=\"label-for-connected-papers\" class=\"lab-toggle\" data-script-url=\"https://static.arxiv.org/static/browse/0.3.4/js/connectedpapers.js\" id=\"connectedpapers-toggle\" type=\"checkbox\"/>\n<span class=\"slider\"></span>\n<span class=\"is-sr-only\">Connected Papers Toggle</span>\n</lab",
        "s</div><li><a accesskey=\"f\" aria-describedby=\"download-button-info\" class=\"abs-button download-pdf\" href=\"/pdf/2311.01449.pdf\">Download PDF</a></li><li><a class=\"abs-button download-ps\" href=\"/ps/2311.01449\">PostScript</a></li><li><a class=\"abs-button download-format\" href=\"/format/2311.01449\">Other Formats</a></li></ul>\n<div class=\"abs-license\"><a href=\"http://creativecommons.org/licenses/by/4.0/\" title=\"Rights to this article\"><img src=\"https://arxiv.org/icons/licenses/by-4.0.png\"/></a></div>\n</div>\n<!--end full-text--> <div class=\"browse\">\n    Current browse context: <div class=\"current\">cs.CL</div>\n<div class=\"prevnext\">\n<span class=\"arrow\">\n<a accesskey=\"p\" class=\"abs-button prev-url\" href=\"/prevnext?id=2311.01449&amp;function=prev&amp;context=cs.CL\" title=\"previous in cs.CL (accesskey p)\">&lt;\u00a0prev</a>\n</span>\n<span class=\"is-hidden-mobile\">\u00a0 | \u00a0</span> <span class=\"arrow\">\n<a accesskey=\"n\" class=\"abs-button next-url\" href=\"/prevnext?id=2311.01449&amp;function=next&amp;context=cs.CL\" title=\"next in cs.CL (accesskey n)\">next\u00a0&gt;</a>\n</span><br/>\n</div><div class=\"list\">\n<a class=\"abs-button abs-button-grey abs-button-small context-new\" href=\"/list/cs.CL/new\">new</a>\n<span class=\"is-hidden-mobile\"> | </span>\n<a class=\"abs-button abs-button-grey abs-button-small context-recent\" href=\"/list/cs.CL/recent\">recent</a>\n<span class=\"is-hidden-mobile\"> | </span>\n<a class=\"abs-button abs-button-grey abs-button-small context-id\" href=\"/list/cs.CL/2311\">2311</a>\n</div><div class=\"abs-switch-cat\">\n    Change to browse by:\n    <div class=\"switch context-change\">\n<a href=\"/abs/2311.01449?context=cs\">cs</a><br class=\"is-hidden-mobile\"/>\n</div>\n</div>\n</div>\n<div class=\"extra-ref-cite\">\n<h3>References &amp; Citations</h3>\n<ul>\n<li><a class=\"abs-button abs-button-small cite-ads\" href=\"https://ui.adsabs.harvard.edu/abs/arXiv:2311.01449\">NASA ADS</a></li><li><a class=\"abs-button abs-button-small cite-google-scholar\" href=\"https://scholar.google.com/scholar_lookup?arxiv_id=2311.01",
        "7v-27zm-27-54v27h27v-27zm27 0v27h27v-27zm0-27v27h27v-27zm27 0v27h27v-27zm0-27v27h27v-27zm27 0v27h27v-27zm-108 81v27h27v-27zm558 54v27h-27v-27zm-27-27v27h27v-27zm27-54v27h27v-27zm-27 0v27h27v-27zm0-27v27h27v-27zm-27 0v27h27v-27zm0-27v27h27v-27zm-27 0v27h27v-27zm108 81v27h27v-27zm0-495h27v27h-27zm-27 27h27v-27h-27zm-54-27h27v-27h-27zm0 27h27v-27h-27zm-27 0h27v-27h-27zm0 27h27v-27h-27zm-27 0h27v-27h-27zm0 27h27v-27h-27zm81-108h27v-27h-27zm-504 45h-27v-27h27zm27-27h-27v27h27zm54-27h-27v27h27zm0 27h-27v27h27zm27 0h-27v27h27zm0 27h-27v27h27zm27 0h-27v27h27zm0 27h-27v27h27zm-81-108h-27v27h27z\" fill=\"#ccc\"></path><path d=\"M598.6 665.1H41.5C-76.5 667 176 280.2 176 280.2h53a46.5 46.5 0 0162.8-56.3 29.2 29.2 0 1128.5 35.9h-1a46.5 46.5 0 01-1.5 20.3l142.5-.1s255.3 387 138.3 385.1zM291 181a29.3 29.3 0 10-29.2-29.3A29.3 29.3 0 00291 181zm65.4-66.8a22.4 22.4 0 10-22.5-22.4 22.4 22.4 0 0022.5 22.4z\" fill=\"#fc0\"></path><path d=\"M245.5 172V10h153v162s324 495 198 495h-558c-126 0 207-495 207-495zm126 54h56m-13 72h56m-9 72h56m-20 72h56m-22 72h56m-29 72h56m-457-45c20.8 41.7 87.3 81 160.7 81 72.1 0 142.1-38.2 163.4-81\" fill=\"none\" stroke=\"#000\" stroke-miterlimit=\"10\" stroke-width=\"20\"></path><path d=\"M273.3 421.7c0 31-9.8 56.3-21.9 56.3s-21.8-25.2-21.8-56.3 9.8-56.3 21.8-56.3 21.9 25.2 21.9 56.3zm114.4-56.3c-12 0-21.8 25.2-21.8 56.3s9.7 56.3 21.8 56.3 21.9-25.2 21.9-56.3-9.8-56.3-21.9-56.3zM150.1 526.6c-18.2 6.7-27.5 22.9-23.2 30.2s14.8-5.5 33-12.2 37.4-4.9 33-12.2-24.5-12.6-42.8-5.8zm296 5.8c-4.2 7.3 14.9 5.5 33.1 12.2s28.7 19.5 33 12.2-5-23.5-23.2-30.2-38.5-1.5-42.8 5.8z\"></path></svg></p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<!-- END LABS AREA -->\n<div class=\"endorsers\">\n<a class=\"endorser-who\" href=\"/auth/show-endorsers/2311.01449\">Which authors of this paper are endorsers?</a> |\n    <a href=\"javascript:setMathjaxCookie()\" id=\"mathjax_toggle\">Disable MathJax</a> (<a href=\"https://info.arxiv.org/help/mathjax.html\">What is MathJax?</a>)\n    <span class=\"help\" style=\"font-style: normal; fl",
        "ic.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg  400w\"/>\n<source srcset=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell_seal_simple_black.svg 2x\"/>\n<img alt=\"Cornell University Logo\" src=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\"/>\n</picture>\n</a></div>\n<div class=\"column nav\" id=\"toggle-container\" role=\"menubar\">\n<button class=\"toggle-control\"><svg class=\"icon filter-white\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\"><title>open search</title><path d=\"M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z\"></path></svg></button>\n<div class=\"mobile-toggle-block toggle-target\">\n<form action=\"https://arxiv.org/search\" class=\"mobile-search-form\" method=\"GET\">\n<div class=\"field has-addons\">\n<input aria-label=\"Search term or terms\" class=\"input\" name=\"query\" placeholder=\"Search...\" type=\"text\">\n<input name=\"source\" type=\"hidden\" value=\"header\"/>\n<input name=\"searchtype\" type=\"hidden\" value=\"all\"/>\n<button class=\"button\">GO</button>\n</input></div>\n</form>\n</div>\n<button class=\"toggle-control\"><svg class=\"icon filter-white\" role=\"menu\" viewbox=\"0 0 448 512\" xmlns=\"http://www.w3.org/2000/svg\"><title>open navigation menu</title><path d=\"M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z\"></path></svg></button>\n<div class=\"mobile-toggle-block toggle-target\">\n<nav aria-labelledby=\"mobilem",
        "media=\"(min-width: 501px)\" sizes=\"400w\" srcset=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg  400w\"/>\n<source srcset=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell_seal_simple_black.svg 2x\"/>\n<img alt=\"Cornell University Logo\" src=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\"/>\n</picture>\n</a></div>\n<div class=\"column nav\" id=\"toggle-container\" role=\"menubar\">\n<button class=\"toggle-control\"><svg class=\"icon filter-white\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\"><title>open search</title><path d=\"M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z\"></path></svg></button>\n<div class=\"mobile-toggle-block toggle-target\">\n<form action=\"https://arxiv.org/search\" class=\"mobile-search-form\" method=\"GET\">\n<div class=\"field has-addons\">\n<input aria-label=\"Search term or terms\" class=\"input\" name=\"query\" placeholder=\"Search...\" type=\"text\">\n<input name=\"source\" type=\"hidden\" value=\"header\"/>\n<input name=\"searchtype\" type=\"hidden\" value=\"all\"/>\n<button class=\"button\">GO</button>\n</input></div>\n</form>\n</div>\n<button class=\"toggle-control\"><svg class=\"icon filter-white\" role=\"menu\" viewbox=\"0 0 448 512\" xmlns=\"http://www.w3.org/2000/svg\"><title>open navigation menu</title><path d=\"M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z\"></path></svg></button>\n<div class=\"mobil",
        "e:width\"/>\n<meta content=\"700\" property=\"og:image:height\"/>\n<meta content=\"arXiv logo\" property=\"og:image:alt\"/>\n<meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal semantic control over topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining. TopicGPT can be further extended to hierarchical topical modeling, enabling users to explore topics at various levels of granularity. By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.' property=\"og:description\"/>\n<meta content=\"@arxiv\" name=\"twitter:site\"/>\n<meta content=\"summary\" name=\"twitter:card\"/>\n<meta content=\"TopicGPT: A Prompt-based Topic Modeling Framework\" name=\"twitter:title\"/>\n<meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to...' name=\"twitter:description\"/>\n<meta content=\"https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png\" name=\"twitter:image\"/>\n<meta content=\"arXiv logo\" name=\"twitter:i"
    ],
    "relevant_snippets": [
        " streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.' property=\"og:description\"/>\n<meta content=\"@arxiv\" name=\"twitter:site\"/>\n<meta content=\"summary\" name=\"twitter:card\"/>\n<meta content=\"TopicGPT: A Prompt-based Topic Modeling Framework\" name=\"twitter:title\"/>\n<meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to...' name=\"twitter:description\"/>\n<meta content=\"https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png\" name=\"twitter:image\"/>\n<meta content=\"arXiv logo\" name=\"twitter:image:alt\"/>\n<link href=\"https://static.arxiv.org/static/browse/0.3.4/css/tooltip.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"><link href=\"https://static.arxiv.org/js/bibex-dev/bibex.css?20200709\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>  \n\n\n\n<meta content=\"TopicGPT: A Prompt-based Topic Modeling Framework\" name=\"citation_title\"/><meta content=\"Pham, Chau Minh\" name=\"citation_author\"/><meta content=\"Hoyle, Alexander\" name=\"citation_author\"/><meta content=\"Sun, Simeng\" name=\"citation_author\"/><meta content=\"Iyyer, Mohit\" name=\"citation_author\"/><meta content=\"2023/11/02\" name=\"citation_date\"/><meta content=\"2023/11/02\" name=\"citation_online_date\"/><meta content=\"https://arxiv.org/pdf/2311.01449.pdf\" name=\"citation_pdf_url\"/><meta content=\"2311.01449\" name=\"citation_arxiv_id\"/><meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal semantic control over topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collectio",
        "e:width\"/>\n<meta content=\"700\" property=\"og:image:height\"/>\n<meta content=\"arXiv logo\" property=\"og:image:alt\"/>\n<meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal semantic control over topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining. TopicGPT can be further extended to hierarchical topical modeling, enabling users to explore topics at various levels of granularity. By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.' property=\"og:description\"/>\n<meta content=\"@arxiv\" name=\"twitter:site\"/>\n<meta content=\"summary\" name=\"twitter:card\"/>\n<meta content=\"TopicGPT: A Prompt-based Topic Modeling Framework\" name=\"twitter:title\"/>\n<meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to...' name=\"twitter:description\"/>\n<meta content=\"https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png\" name=\"twitter:image\"/>\n<meta content=\"arXiv logo\" name=\"twitter:i"
    ],
    "generated_code_tries": [
        {
            "attempt": 1,
            "code": "END_CODE\n\nimport bs4 \n\ndef scraper(url: str) -> str:\n  # Make request to the URL\n  res = requests.get(url)\n\n  # Use BeautifulSoup to parse the HTML\n  soup = bs4.BeautifulSoup(res.text, 'html.parser')\n\n  # Extract paper_title\n  paper_title = soup.find('meta', attrs={'name': 'citation_title'})['content']\n\n  # Extract authors\n  author_names = []\n  author_tags = soup.find_all('meta', attrs={'name': 'citation_author'})\n  for tag in author_tags:\n    author_names.append(tag['content'])\n\n  # Extract abstract\n  abstract = soup.find('meta', attrs={'name': 'citation_abstract'})['content']\n\n  # Build dictionary with extracted data\n  data = {\n      'paper_title': paper_title,\n      'authors': author_names,\n      'abstract': abstract\n  }\n\n  # Convert dictionary to JSON and print out\n  print(json.dumps(data, indent=4))\n\nif __name__ == '__main__':\n  url = \"https://arxiv.org/abs/2311.01449\"\n  scraper(url)",
            "error": "Error on line 1: END_CODE\nNameError: name 'END_CODE' is not defined",
            "debugging_info": "Possible fix:\n\nIt seems that the code is missing the closing of the function `scraper()`, ending the code with `END_CODE` or missing the closing brace `}`. To fix this error, you can add a closing brace `}` at the end of the `scraper()` function, as well as adding a closing brace `}` at the end of the `if __name__ == '__main__':` block. Your code should look like this:\n\n```\nimport bs4 \n\ndef scraper(url: str) -> str:\n  # Make request to the URL\n  res = requests.get(url)\n\n  # Use BeautifulSoup to parse the HTML\n  soup = bs4.BeautifulSoup(res.text, 'html.parser')\n\n  # Extract paper_title\n  paper_title = soup.find('meta', attrs={'name': 'citation_title'})['content']\n\n  # Extract authors\n  author_names = []\n  author_tags = soup.find_all('meta', attrs={'name': 'citation_author'})\n  for tag in author_tags:\n    author_names.append(tag['content'])\n\n  # Extract abstract\n  abstract = soup.find('meta', attrs={'name': 'citation_abstract'})['content']\n\n  # Build dictionary with extracted data\n  data = {\n      'paper_title': paper_title,\n      'authors': author_names,\n      'abstract': abstract\n  }\n\n  # Convert dictionary to JSON and print out\n  print(json.dumps(data, indent=4))\n\nif __name__ == '__main__':\n  url = \"https://arxiv.org/abs/2311.01449\"\n  scraper(url)\n```\n\nAlternatively, you can use the `END_CODE` as a comment instead of an actual code, by adding a `#` at the beginning of the line, like this:\n\n```\nimport bs4 \n\ndef scraper(url: str) -> str:\n  # Make request to the URL\n  res = requests.get(url)\n\n  # Use BeautifulSoup to parse the HTML\n  soup = bs4.BeautifulSoup(res.text, 'html.parser')\n\n  # Extract paper_title\n  paper_title = soup.find('meta', attrs={'name': 'citation_title'})['content']\n\n  # Extract authors\n  author_names = []\n  author_tags = soup.find_all('meta', attrs={'name': 'citation_author'})\n  for tag in author_tags:\n    author_names.append(tag['content'])\n\n  # Extract abstract\n  abstract = soup.find('meta', attrs={'name': 'citation_abstract'})['content']\n\n  # Build dictionary with extracted data\n  data = {\n      'paper_title': paper_title,\n      'authors': author_names,\n      'abstract': abstract\n  }\n\n  # Convert dictionary to JSON and print out\n  print(json.dumps(data, indent=4))\n\nif __name__ == '__main__':\n  url = \"https://arxiv.org/abs/2311.01449\"\n  scraper(url) #END_CODE\n```\n\nWhichever fix you choose to apply, the important thing is to make sure that the code is properly formatted and all functions and blocks are closed. "
        },
        {
            "attempt": 2,
            "code": "import bs4 \n\ndef scraper(url: str) -> str:\n  # Make request to the URL\n  res = requests.get(url)\n\n  # Use BeautifulSoup to parse the HTML\n  soup = bs4.BeautifulSoup(res.text, 'html.parser')\n\n  # Extract paper_title\n  paper_title = soup.find('meta', attrs={'name': 'citation_title'})['content']\n\n  # Extract authors\n  author_names = []\n  author_tags = soup.find_all('meta', attrs={'name': 'citation_author'})\n  for tag in author_tags:\n    author_names.append(tag['content'])\n\n  # Extract abstract\n  abstract = soup.find('meta', attrs={'name': 'citation_abstract'})['content']\n\n  # Build dictionary with extracted data\n  data = {\n      'paper_title': paper_title,\n      'authors': author_names,\n      'abstract': abstract\n  }\n\n  # Convert dictionary to JSON and print out\n  print(json.dumps(data, indent=4))\n\nif __name__ == '__main__':\n  url = \"https://arxiv.org/abs/2311.01449\"\n  scraper(url) END_CODE",
            "error": "Error on line 34:   scraper(url) END_CODE\nSyntaxError: invalid syntax (<string>, line 34)",
            "debugging_info": "The code appears to be missing an indentation before the line \"END_CODE\" at the end of the file. To fix this error, the line should be indented to match the indentation of the rest of the code, like this:\n\n```if __name__ == '__main__':\n  url = \"https://arxiv.org/abs/2311.01449\"\n  scraper(url) \n  END_CODE```"
        },
        {
            "attempt": 3,
            "code": "# imports\nimport bs4 \nimport requests\nimport json\n\ndef scraper(url: str) -> str:\n  # Make request to the URL\n  res = requests.get(url)\n\n  # Use BeautifulSoup to parse the HTML\n  soup = bs4.BeautifulSoup(res.text, 'html.parser')\n\n  # Extract paper_title\n  paper_title = soup.find('meta', attrs={'name': 'citation_title'})['content']\n\n  # Extract authors\n  author_names = []\n  author_tags = soup.find_all('meta', attrs={'name': 'citation_author'})\n  for tag in author_tags:\n    author_names.append(tag['content'])\n\n  # Extract abstract\n  abstract = soup.find('meta', attrs={'name': 'citation_abstract'})['content']\n\n  # Build dictionary with extracted data\n  data = {\n      'paper_title': paper_title,\n      'authors': author_names,\n      'abstract': abstract\n  }\n\n  # Convert dictionary to JSON and print out\n  print(json.dumps(data, indent=4))\n\nif __name__ == '__main__':\n  url = \"https://arxiv.org/abs/2311.01449\"\n  scraper(url)",
            "error": "",
            "debugging_info": ""
        }
    ],
    "final_scraper_code": null,
    "test_count": [],
    "test_succ_count": [],
    "test_results": {}
}