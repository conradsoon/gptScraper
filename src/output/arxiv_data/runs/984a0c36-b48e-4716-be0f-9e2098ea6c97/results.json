{
    "dataset": "../output/arxiv_data",
    "run": "984a0c36-b48e-4716-be0f-9e2098ea6c97",
    "source": "",
    "snippets_used": 2,
    "attempts": 1,
    "final_scraper_code": "# imports\nimport requests\nfrom bs4 import BeautifulSoup\nimport json \n\ndef scraper(url: str) -> str:\n  # request webpage\n  r = requests.get(url)\n  soup = BeautifulSoup(r.content, 'html.parser')\n\n  # extract paper_title\n  paper_title = soup.find('h1', class_='title mathjax').text.strip()\n\n  # extract authors\n  authors = []\n  author_elem = soup.find('div', class_='authors')\n  for a in author_elem.find_all('a'):\n    if a.get('title') == 'Author Profile Page':\n      continue\n    authors.append(a.text.strip())\n\n  # extract abstract\n  abstract = soup.find('blockquote', class_='abstract mathjax').text.strip()\n\n  # create dictionary object\n  data = {\n    'paper_title': paper_title,\n    'authors': authors,\n    'abstract': abstract\n  }\n\n  # print json data\n  print(json.dumps(data, indent=2))\n\n  return \"Data successfully scraped and printed as JSON\"\n\nif __name__ == '__main__':\n  url = \"https://arxiv.org/abs/2311.01449\"\n  scraper(url)",
    "test_count": 20,
    "test_succ_count": 14
}