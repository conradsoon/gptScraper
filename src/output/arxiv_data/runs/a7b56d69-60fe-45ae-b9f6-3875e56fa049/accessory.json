{
    "dataset": "../output/arxiv_data",
    "run": "a7b56d69-60fe-45ae-b9f6-3875e56fa049",
    "source": "",
    "snippets_used": 3,
    "attempts": 2,
    "snippets_tried": [
        "iv class=\"field has-addons\">\n<div class=\"control\">\n<input aria-label=\"Search term or terms\" class=\"input is-small\" name=\"query\" placeholder=\"Search...\" type=\"text\"/>\n<p class=\"help\"><a href=\"https://info.arxiv.org/help\">Help</a> | <a href=\"https://arxiv.org/search/advanced\">Advanced Search</a></p>\n</div>\n<div class=\"control\">\n<div class=\"select is-small\">\n<select aria-label=\"Field to search\" name=\"searchtype\">\n<option selected=\"selected\" value=\"all\">All fields</option>\n<option value=\"title\">Title</option>\n<option value=\"author\">Author</option>\n<option value=\"abstract\">Abstract</option>\n<option value=\"comments\">Comments</option>\n<option value=\"journal_ref\">Journal reference</option>\n<option value=\"acm_class\">ACM classification</option>\n<option value=\"msc_class\">MSC classification</option>\n<option value=\"report_num\">Report number</option>\n<option value=\"paper_id\">arXiv identifier</option>\n<option value=\"doi\">DOI</option>\n<option value=\"orcid\">ORCID</option>\n<option value=\"author_id\">arXiv author ID</option>\n<option value=\"help\">Help pages</option>\n<option value=\"full_text\">Full text</option>\n</select>\n</div>\n</div>\n<input name=\"source\" type=\"hidden\" value=\"header\"/>\n<button class=\"button is-small is-cul-darker\">Search</button>\n</div>\n</form>\n</div>\n</div><!-- /end desktop header -->\n<div class=\"mobile-header\">\n<div class=\"columns is-mobile\">\n<div class=\"column logo-arxiv\"><a href=\"https://arxiv.org/\"><img alt=\"arXiv logo\" src=\"https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg\" style=\"height:60px;\"/></a></div>\n<div class=\"column logo-cornell\"><a href=\"https://www.cornell.edu/\">\n<picture>\n<source media=\"(min-width: 501px)\" sizes=\"400w\" srcset=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg  400w\"/>\n<source srcset=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell_seal_simple_black.svg 2x\"/>\n<img alt=\"Cornell University Logo\" src=\"https://static.arxiv.org/static/browse/0.3.4",
        "jax\">\n<span class=\"descriptor\">Abstract:</span>Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal semantic control over topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining. TopicGPT can be further extended to hierarchical topical modeling, enabling users to explore topics at various levels of granularity. By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.\n    </blockquote>\n<!--CONTEXT-->\n<div class=\"metatable\">\n<table summary=\"Additional metadata\"><tr>\n<td class=\"tablecell label\">Subjects:</td>\n<td class=\"tablecell subjects\">\n<span class=\"primary-subject\">Computation and Language (cs.CL)</span></td>\n</tr><tr>\n<td class=\"tablecell label\">Cite as:</td>\n<td class=\"tablecell arxivid\"><span class=\"arxivid\"><a href=\"https://arxiv.org/abs/2311.01449\">arXiv:2311.01449</a> [cs.CL]</span></td>\n</tr>\n<tr>\n<td class=\"tablecell label\">\u00a0</td>\n<td class=\"tablecell arxividv\">(or <span class=\"arxivid\">\n<a href=\"https://arxiv.org/abs/2311.01449v1\">arXiv:2311.01449v1</a> [cs.CL]</span> for this version)\n          </td>\n</tr> <tr>\n<td class=\"ta",
        "e for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal semantic control over topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining. TopicGPT can be further extended to hierarchical topical modeling, enabling users to explore topics at various levels of granularity. By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.' name=\"citation_abstract\"/>\n</link></meta></meta></meta></link></link></link></link></head>\n<body class=\"with-cu-identity\">\n<div class=\"flex-wrap-footer\">\n<header>\n<a class=\"is-sr-only\" href=\"#content\">Skip to main content</a>\n<!-- start desktop header -->\n<div class=\"columns is-vcentered is-hidden-mobile\" id=\"cu-identity\">\n<div class=\"column\" id=\"cu-logo\">\n<a href=\"https://www.cornell.edu/\"><img alt=\"Cornell University\" src=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\"/></a>\n</div><div class=\"column\" id=\"support-ack\">\n<span id=\"support-ack-url\">We gratefully acknowledge support from the Simons Foundation, <a href=\"https://info.arxiv.org/about/ourmembers.html\">member institutions</a>, and all contributors. <a href=\"",
        "n class=\"slider\"></span>\n<span class=\"is-sr-only\">Spaces Toggle</span>\n</label>\n</div>\n<div class=\"column lab-name\">\n<span id=\"label-for-spaces\">Hugging Face Spaces</span> <em>(<a href=\"https://huggingface.co/docs/hub/spaces\" target=\"_blank\">What is Spaces?</a>)</em>\n</div>\n</div>\n</div>\n<div id=\"replicate-output\"></div>\n<div id=\"spaces-output\"></div>\n</div>\n<input id=\"tabfour\" name=\"tabs\" type=\"radio\"/>\n<label for=\"tabfour\">Related Papers</label>\n<div class=\"tab\">\n<h1>Recommenders and Search Tools</h1>\n<div class=\"toggle\">\n<div class=\"columns is-mobile lab-row\">\n<div class=\"column lab-switch\">\n<label class=\"switch\">\n<input aria-labelledby=\"label-for-influenceflower\" class=\"lab-toggle\" data-script-url=\"https://static.arxiv.org/static/browse/0.3.4/js/influenceflower.js\" id=\"influenceflower-toggle\" type=\"checkbox\"/>\n<span class=\"slider\"></span>\n<span class=\"is-sr-only\">Link to Influence Flower</span>\n</label>\n</div>\n<div class=\"column lab-name\">\n<span id=\"label-for-influenceflower\">Influence Flower</span> <em>(<a href=\"https://influencemap.cmlab.dev/\" target=\"_blank\">What are Influence Flowers?</a>)</em>\n</div>\n</div>\n<div class=\"columns is-mobile lab-row\">\n<div class=\"column lab-switch\">\n<label class=\"switch\">\n<input aria-labelledby=\"label-for-connected-papers\" class=\"lab-toggle\" data-script-url=\"https://static.arxiv.org/static/browse/0.3.4/js/connectedpapers.js\" id=\"connectedpapers-toggle\" type=\"checkbox\"/>\n<span class=\"slider\"></span>\n<span class=\"is-sr-only\">Connected Papers Toggle</span>\n</label>\n</div>\n<div class=\"column lab-name\">\n<span id=\"label-for-connected-papers\">Connected Papers</span> <em>(<a href=\"https://www.connectedpapers.com/about\" target=\"_blank\">What is Connected Papers?</a>)</em>\n</div>\n</div>\n<div class=\"columns is-mobile lab-row\">\n<div class=\"column lab-switch\">\n<label class=\"switch\">\n<input aria-labelledby=\"label-for-core\" class=\"lab-toggle\" id=\"core-recommender-toggle\" type=\"checkbox\"/>\n<span class=\"slider\"></span>\n<span class=\"is-sr-only\">Co",
        "owse/0.3.4/js/connectedpapers.js\" id=\"connectedpapers-toggle\" type=\"checkbox\"/>\n<span class=\"slider\"></span>\n<span class=\"is-sr-only\">Connected Papers Toggle</span>\n</label>\n</div>\n<div class=\"column lab-name\">\n<span id=\"label-for-connected-papers\">Connected Papers</span> <em>(<a href=\"https://www.connectedpapers.com/about\" target=\"_blank\">What is Connected Papers?</a>)</em>\n</div>\n</div>\n<div class=\"columns is-mobile lab-row\">\n<div class=\"column lab-switch\">\n<label class=\"switch\">\n<input aria-labelledby=\"label-for-core\" class=\"lab-toggle\" id=\"core-recommender-toggle\" type=\"checkbox\"/>\n<span class=\"slider\"></span>\n<span class=\"is-sr-only\">Core recommender toggle</span>\n</label>\n</div>\n<div class=\"column lab-name\">\n<span id=\"label-for-core\">CORE Recommender</span> <em>(<a href=\"https://core.ac.uk/services/recommender\">What is CORE?</a>)</em>\n</div>\n</div></div>\n<div id=\"influenceflower-output\"></div>\n<div id=\"influenceflower-output-graph\" style=\"display:none\">\n<ul class=\"flower-tabs\">\n<li class=\"active\"><a class=\"btn tab-btn\" onclick=\"openTab(event, 'tab-author')\">Author</a></li>\n<li><a class=\"btn tab-btn\" onclick=\"openTab(event, 'tab-venue')\">Venue</a></li>\n<li><a class=\"btn tab-btn\" onclick=\"openTab(event, 'tab-inst')\">Institution</a></li>\n<li><a class=\"btn tab-btn\" onclick=\"openTab(event, 'tab-topic')\">Topic</a></li>\n</ul>\n<div class=\"flower-tab-content\">\n<div class=\"tab-flower active\" id=\"tab-author\"><svg id=\"flower-graph-author\"></svg></div>\n<div class=\"tab-flower\" id=\"tab-venue\"><svg id=\"flower-graph-venue\"></svg></div>\n<div class=\"tab-flower\" id=\"tab-inst\"><svg id=\"flower-graph-inst\"></svg></div>\n<div class=\"tab-flower\" id=\"tab-topic\"><svg id=\"flower-graph-topic\"></svg></div>\n</div>\n</div>\n<div id=\"connectedpapers-output\" style=\"min-height: 15px\"></div>\n<div id=\"coreRecommenderOutput\"></div>\n<div id=\"iarxivOutput\"></div>\n</div>\n<input id=\"tabfive\" name=\"tabs\" type=\"radio\"/>\n<label for=\"tabfive\">\n        About arXivLabs\n      </label>\n<div class=\"tab\">\n<div cla",
        "trol\"><svg class=\"icon filter-white\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\"><title>open search</title><path d=\"M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z\"></path></svg></button>\n<div class=\"mobile-toggle-block toggle-target\">\n<form action=\"https://arxiv.org/search\" class=\"mobile-search-form\" method=\"GET\">\n<div class=\"field has-addons\">\n<input aria-label=\"Search term or terms\" class=\"input\" name=\"query\" placeholder=\"Search...\" type=\"text\">\n<input name=\"source\" type=\"hidden\" value=\"header\"/>\n<input name=\"searchtype\" type=\"hidden\" value=\"all\"/>\n<button class=\"button\">GO</button>\n</input></div>\n</form>\n</div>\n<button class=\"toggle-control\"><svg class=\"icon filter-white\" role=\"menu\" viewbox=\"0 0 448 512\" xmlns=\"http://www.w3.org/2000/svg\"><title>open navigation menu</title><path d=\"M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z\"></path></svg></button>\n<div class=\"mobile-toggle-block toggle-target\">\n<nav aria-labelledby=\"mobilemenulabel\" class=\"mobile-menu\">\n<h2 id=\"mobilemenulabel\">quick links</h2>\n<ul>\n<li><a href=\"https://arxiv.org/login\">Login</a></li>\n<li><a href=\"https://info.arxiv.org/help\">Help Pages</a></li>\n<li><a href=\"https://info.arxiv.org/about\">About</a></li>\n</ul>\n</nav>\n</div>\n</div>\n</div>\n</div><!-- /end mobile-header -->\n</header>\n<main>\n<div id=\"content\">\n<!--\nrdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n         xmlns:dc=\"http:",
        "dels (LLMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining. TopicGPT can be further extended to hierarchical topical modeling, enabling users to explore topics at various levels of granularity. By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.' name=\"citation_abstract\"/>\n</link></meta></meta></meta></link></link></link></link></head>\n<body class=\"with-cu-identity\">\n<div class=\"flex-wrap-footer\">\n<header>\n<a class=\"is-sr-only\" href=\"#content\">Skip to main content</a>\n<!-- start desktop header -->\n<div class=\"columns is-vcentered is-hidden-mobile\" id=\"cu-identity\">\n<div class=\"column\" id=\"cu-logo\">\n<a href=\"https://www.cornell.edu/\"><img alt=\"Cornell University\" src=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\"/></a>\n</div><div class=\"column\" id=\"support-ack\">\n<span id=\"support-ack-url\">We gratefully acknowledge support from the Simons Foundation, <a href=\"https://info.arxiv.org/about/ourmembers.html\">member institutions</a>, and all contributors. <a href=\"https://info.arxiv.org/about/donate.html\">Donate</a></span>\n</div>\n</div>\n<div class=\"is-hidden-mobile\" id=\"header\">\n<a aria-hidden=\"true\" href=\"{url_path('ignore_me')}\"></a>\n<div class=\"header-breadcrumbs is-hidden-mobile\">\n<a href=\"/\"><img alt=\"arxiv logo\" src=\"https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-o",
        "property=\"og:description\"/>\n<meta content=\"@arxiv\" name=\"twitter:site\"/>\n<meta content=\"summary\" name=\"twitter:card\"/>\n<meta content=\"TopicGPT: A Prompt-based Topic Modeling Framework\" name=\"twitter:title\"/>\n<meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to...' name=\"twitter:description\"/>\n<meta content=\"https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png\" name=\"twitter:image\"/>\n<meta content=\"arXiv logo\" name=\"twitter:image:alt\"/>\n<link href=\"https://static.arxiv.org/static/browse/0.3.4/css/tooltip.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"><link href=\"https://static.arxiv.org/js/bibex-dev/bibex.css?20200709\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>  \n\n\n\n<meta content=\"TopicGPT: A Prompt-based Topic Modeling Framework\" name=\"citation_title\"/><meta content=\"Pham, Chau Minh\" name=\"citation_author\"/><meta content=\"Hoyle, Alexander\" name=\"citation_author\"/><meta content=\"Sun, Simeng\" name=\"citation_author\"/><meta content=\"Iyyer, Mohit\" name=\"citation_author\"/><meta content=\"2023/11/02\" name=\"citation_date\"/><meta content=\"2023/11/02\" name=\"citation_online_date\"/><meta content=\"https://arxiv.org/pdf/2311.01449.pdf\" name=\"citation_pdf_url\"/><meta content=\"2311.01449\" name=\"citation_arxiv_id\"/><meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal semantic control over topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic m",
        "/02\" name=\"citation_online_date\"/><meta content=\"https://arxiv.org/pdf/2311.01449.pdf\" name=\"citation_pdf_url\"/><meta content=\"2311.01449\" name=\"citation_arxiv_id\"/><meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal semantic control over topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining. TopicGPT can be further extended to hierarchical topical modeling, enabling users to explore topics at various levels of granularity. By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.' name=\"citation_abstract\"/>\n</link></meta></meta></meta></link></link></link></link></head>\n<body class=\"with-cu-identity\">\n<div class=\"flex-wrap-footer\">\n<header>\n<a class=\"is-sr-only\" href=\"#content\">Skip to main content</a>\n<!-- start desktop header -->\n<div class=\"columns is-vcentered is-hidden-mobile\" id=\"cu-identity\">\n<div class=\"column\" id=\"cu-logo\">\n<a href=\"https://www.cornell.edu/\"><img alt=\"Cornell University\" src=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\"/></a>\n</div><div class=\"c",
        "ion</option>\n<option value=\"msc_class\">MSC classification</option>\n<option value=\"report_num\">Report number</option>\n<option value=\"paper_id\">arXiv identifier</option>\n<option value=\"doi\">DOI</option>\n<option value=\"orcid\">ORCID</option>\n<option value=\"author_id\">arXiv author ID</option>\n<option value=\"help\">Help pages</option>\n<option value=\"full_text\">Full text</option>\n</select>\n</div>\n</div>\n<input name=\"source\" type=\"hidden\" value=\"header\"/>\n<button class=\"button is-small is-cul-darker\">Search</button>\n</div>\n</form>\n</div>\n</div><!-- /end desktop header -->\n<div class=\"mobile-header\">\n<div class=\"columns is-mobile\">\n<div class=\"column logo-arxiv\"><a href=\"https://arxiv.org/\"><img alt=\"arXiv logo\" src=\"https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg\" style=\"height:60px;\"/></a></div>\n<div class=\"column logo-cornell\"><a href=\"https://www.cornell.edu/\">\n<picture>\n<source media=\"(min-width: 501px)\" sizes=\"400w\" srcset=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg  400w\"/>\n<source srcset=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell_seal_simple_black.svg 2x\"/>\n<img alt=\"Cornell University Logo\" src=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\"/>\n</picture>\n</a></div>\n<div class=\"column nav\" id=\"toggle-container\" role=\"menubar\">\n<button class=\"toggle-control\"><svg class=\"icon filter-white\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\"><title>open search</title><path d=\"M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z\"></path></svg></button>\n<div class=\"mobile-toggle-block toggle-target\">\n<form action=\"https://ar",
        "me=\"twitter:title\"/>\n<meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to...' name=\"twitter:description\"/>\n<meta content=\"https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png\" name=\"twitter:image\"/>\n<meta content=\"arXiv logo\" name=\"twitter:image:alt\"/>\n<link href=\"https://static.arxiv.org/static/browse/0.3.4/css/tooltip.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"><link href=\"https://static.arxiv.org/js/bibex-dev/bibex.css?20200709\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>  \n\n\n\n<meta content=\"TopicGPT: A Prompt-based Topic Modeling Framework\" name=\"citation_title\"/><meta content=\"Pham, Chau Minh\" name=\"citation_author\"/><meta content=\"Hoyle, Alexander\" name=\"citation_author\"/><meta content=\"Sun, Simeng\" name=\"citation_author\"/><meta content=\"Iyyer, Mohit\" name=\"citation_author\"/><meta content=\"2023/11/02\" name=\"citation_date\"/><meta content=\"2023/11/02\" name=\"citation_online_date\"/><meta content=\"https://arxiv.org/pdf/2311.01449.pdf\" name=\"citation_pdf_url\"/><meta content=\"2311.01449\" name=\"citation_arxiv_id\"/><meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal semantic control over topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in"
    ],
    "relevant_snippets": [
        "e for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal semantic control over topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining. TopicGPT can be further extended to hierarchical topical modeling, enabling users to explore topics at various levels of granularity. By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.' name=\"citation_abstract\"/>\n</link></meta></meta></meta></link></link></link></link></head>\n<body class=\"with-cu-identity\">\n<div class=\"flex-wrap-footer\">\n<header>\n<a class=\"is-sr-only\" href=\"#content\">Skip to main content</a>\n<!-- start desktop header -->\n<div class=\"columns is-vcentered is-hidden-mobile\" id=\"cu-identity\">\n<div class=\"column\" id=\"cu-logo\">\n<a href=\"https://www.cornell.edu/\"><img alt=\"Cornell University\" src=\"https://static.arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\"/></a>\n</div><div class=\"column\" id=\"support-ack\">\n<span id=\"support-ack-url\">We gratefully acknowledge support from the Simons Foundation, <a href=\"https://info.arxiv.org/about/ourmembers.html\">member institutions</a>, and all contributors. <a href=\"",
        "trol\"><svg class=\"icon filter-white\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\"><title>open search</title><path d=\"M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z\"></path></svg></button>\n<div class=\"mobile-toggle-block toggle-target\">\n<form action=\"https://arxiv.org/search\" class=\"mobile-search-form\" method=\"GET\">\n<div class=\"field has-addons\">\n<input aria-label=\"Search term or terms\" class=\"input\" name=\"query\" placeholder=\"Search...\" type=\"text\">\n<input name=\"source\" type=\"hidden\" value=\"header\"/>\n<input name=\"searchtype\" type=\"hidden\" value=\"all\"/>\n<button class=\"button\">GO</button>\n</input></div>\n</form>\n</div>\n<button class=\"toggle-control\"><svg class=\"icon filter-white\" role=\"menu\" viewbox=\"0 0 448 512\" xmlns=\"http://www.w3.org/2000/svg\"><title>open navigation menu</title><path d=\"M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z\"></path></svg></button>\n<div class=\"mobile-toggle-block toggle-target\">\n<nav aria-labelledby=\"mobilemenulabel\" class=\"mobile-menu\">\n<h2 id=\"mobilemenulabel\">quick links</h2>\n<ul>\n<li><a href=\"https://arxiv.org/login\">Login</a></li>\n<li><a href=\"https://info.arxiv.org/help\">Help Pages</a></li>\n<li><a href=\"https://info.arxiv.org/about\">About</a></li>\n</ul>\n</nav>\n</div>\n</div>\n</div>\n</div><!-- /end mobile-header -->\n</header>\n<main>\n<div id=\"content\">\n<!--\nrdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n         xmlns:dc=\"http:",
        "me=\"twitter:title\"/>\n<meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to...' name=\"twitter:description\"/>\n<meta content=\"https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png\" name=\"twitter:image\"/>\n<meta content=\"arXiv logo\" name=\"twitter:image:alt\"/>\n<link href=\"https://static.arxiv.org/static/browse/0.3.4/css/tooltip.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"><link href=\"https://static.arxiv.org/js/bibex-dev/bibex.css?20200709\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>  \n\n\n\n<meta content=\"TopicGPT: A Prompt-based Topic Modeling Framework\" name=\"citation_title\"/><meta content=\"Pham, Chau Minh\" name=\"citation_author\"/><meta content=\"Hoyle, Alexander\" name=\"citation_author\"/><meta content=\"Sun, Simeng\" name=\"citation_author\"/><meta content=\"Iyyer, Mohit\" name=\"citation_author\"/><meta content=\"2023/11/02\" name=\"citation_date\"/><meta content=\"2023/11/02\" name=\"citation_online_date\"/><meta content=\"https://arxiv.org/pdf/2311.01449.pdf\" name=\"citation_pdf_url\"/><meta content=\"2311.01449\" name=\"citation_arxiv_id\"/><meta content='Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal semantic control over topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in"
    ],
    "generated_code_tries": [
        {
            "attempt": 1,
            "code": "def print_json(title, authors, abstract):\n    json = {\n        \"title\": title,\n        \"authors\": authors,\n        \"abstract\": abstract\n    }\n    print(json)\n\ndef scraper(url: str) -> None:\n    # Get webpage\n    res = requests.get(url)\n    soup = bs4.BeautifulSoup(res.text, 'html.parser')\n\n    # Extract title\n    titleTag = soup.find(\"meta\", {\"name\": \"citation_title\"})\n    title = titleTag['content']\n\n    # Extract authors\n    authorsTag = soup.find_all(\"meta\", {\"name\": \"citation_author\"})\n    authors = []\n    for authorTag in authorsTag:\n        authors.append(authorTag['content'])\n\n    # Extract abstract\n    abstractTag = soup.find(\"meta\", {\"name\": \"twitter:description\"})\n    abstract = abstractTag['content']\n\n    # Print JSON\n    print_json(title, authors, abstract)",
            "error": "Error on line 12:     soup = bs4.BeautifulSoup(res.text, 'html.parser')\nNameError: name 'bs4' is not defined",
            "debugging_info": "To fix the error, one would need to import the necessary library, 'bs4', in order to use the BeautifulSoup function in the code. This can be done by adding the line `import bs4` at the top of the code, alongside the existing `import requests` line. This will ensure that the BeautifulSoup function is recognized and the code can be executed without any errors."
        },
        {
            "attempt": 2,
            "code": "# imports\nimport bs4 \nimport requests\n\ndef print_json(title, authors, abstract):\n    json = {\n        \"title\": title,\n        \"authors\": authors,\n        \"abstract\": abstract\n    }\n    print(json)\n\ndef scraper(url: str) -> None:\n    # Get webpage\n    res = requests.get(url)\n    soup = bs4.BeautifulSoup(res.text, 'html.parser')\n\n    # Extract title\n    titleTag = soup.find(\"meta\", {\"name\": \"citation_title\"})\n    title = titleTag['content']\n\n    # Extract authors\n    authorsTag = soup.find_all(\"meta\", {\"name\": \"citation_author\"})\n    authors = []\n    for authorTag in authorsTag:\n        authors.append(authorTag['content'])\n\n    # Extract abstract\n    abstractTag = soup.find(\"meta\", {\"name\": \"twitter:description\"})\n    abstract = abstractTag['content']\n\n    # Print JSON\n    print_json(title, authors, abstract)\n\nif __name__ == '__main__':\n  url = \"https://arxiv.org/abs/2311.01449\"\n  scraper(url)",
            "error": "",
            "debugging_info": ""
        }
    ],
    "final_scraper_code": null,
    "test_count": [],
    "test_succ_count": [],
    "test_results": {}
}