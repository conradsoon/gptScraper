{
    "dataset": "stack_exchange_2",
    "run": "a21200d2-169d-4d28-8c36-4f483905ed7c",
    "source": "",
    "snippets_used": 1,
    "attempts": 7,
    "final_scraper_code": "# imports\nimport bs4\nimport requests\nimport json\n\n\ndef scraper(url: str) -> str:\n    # Make a GET request to the specified URL\n    response = requests.get(url)\n\n    # Create a soup object from the response's text content\n    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n\n    # Find all div elements with the s-post-summary class\n    question_items = soup.find_all('div', class_='s-post-summary')\n\n    # Create an empty list to store the data\n    data = []\n\n    # Loop through each question item\n    for item in question_items:\n\n        # Find the question title, tags, and user name\n        question_title = item.find('h3', class_='s-post-summary--content-title').text.strip()\n        tags = [tag.text.strip() for tag in item.find_all('a', class_='post-tag')]\n\n        # Check if the user-details span exists before attempting to find the user name\n        # Assign a default value of None if it does not exist\n        user_name = None\n        if item.find('span', class_='user-details'):\n            user_name = item.find('span', class_='user-details').find('a', class_='s-link').text.strip()\n\n        # Create a dictionary to store the extracted data and append it to the list\n        question_data = {'question_title': question_title, 'tags': tags, 'user_name': user_name}\n        data.append(question_data)\n\n    # Print out the data in JSON format\n    print(json.dumps(data, indent=2))\n\n\nif __name__ == '__main__':\n    url = \"https://math.stackexchange.com/questions\"\n    scraper(url)",
    "test_count": 20,
    "test_succ_count": 18
}