{
    "dataset": "stack_exchange",
    "run": "83d8eccf-4a41-4f87-b54e-be36401f35ff",
    "source": "",
    "snippets_used": 3,
    "attempts": 5,
    "final_scraper_code": "# imports\nimport bs4\nimport requests\nimport json\n\ndef scraper(url: str) -> str:\n    # make a get request to the url\n    response = requests.get(url)\n\n    # use BeautifulSoup to parse the html\n    soup = bs4.BeautifulSoup(response.text, 'html.parser')\n\n    # find all the question-summary divs which contain all the information we need\n    question_summaries = soup.find_all('div', {'class': 'question-summary'})\n\n    # create an empty list to store the results\n    results = []\n\n    # check if the question_summaries list is not empty\n    if len(question_summaries) > 0:\n\n        # loop through each question-summary div\n        for question in question_summaries:\n\n            # extract the title\n            question_title = question.find('a', {'class': 'question-hyperlink'}).text.strip()\n\n            # extract the tags\n            tags = [tag.text for tag in question.find_all('a', {'class': 'post-tag'})]\n\n            # extract the user name\n            user_name = question.find('a', {'class': 'user-details'}).text.strip()\n\n            # extract the number of votes\n            votes = int(question.find('span', {'class': 'vote-count-post'}).text)\n\n            # extract the number of answers\n            answers = int(question.find('div', {'class': 'status'}).text.strip().split()[0])\n\n            # extract the number of views\n            views = int(question.find('div', {'class': 'views'}).text.strip().split()[0])\n\n            # extract the timestamp\n            timestamp = question.find('span', {'class': 'relativetime'})['title']\n\n            # create a dictionary with the extracted information\n            result = {\n                'question_title': question_title,\n                'tags': tags,\n                'user_name': user_name,\n                'votes': votes,\n                'answers': answers,\n                'views': views,\n                'timestamp': timestamp\n            }\n\n            # append the dictionary to the results list\n            results.append(result)\n\n        # convert the list to json\n        results_json = json.dumps(results)\n\n        # print out the json\n        print(results_json)\n\n    else:\n        # if question_summaries list is empty, print an error message\n        print(\"No data was extracted. Please check the scraping logic.\")\n\nif __name__ == '__main__':\n    url = \"https://math.stackexchange.com/questions\"\n    scraper(url)",
    "test_count": 20,
    "test_succ_count": 5
}