{
    "dataset": "stack_exchange",
    "run": "d13e74dc-a566-4ffa-81fe-c714d7273175",
    "source": "",
    "snippets_used": 1,
    "attempts": 8,
    "final_scraper_code": "\n# Imports\nimport requests\nimport bs4\nimport json\n\n# Function to scrape the website\ndef scraper(url: str) -> str:\n  # Send get request to the URL\n  response = requests.get(url)\n\n  # Use BeautifulSoup to parse the response\n  soup = bs4.BeautifulSoup(response.text, 'html.parser')\n\n  # Check response status code\n  if response.status_code != 200:\n    print(\"Error: Response code is not 200.\")\n    print(\"Debugging info:\")\n    print(response.text)\n    return\n\n  # Find all div elements with class 'question-summary'\n  question_list = soup.find_all('div', class_ = 'question-summary')\n\n  # Create empty list to store question data\n  questions = []\n\n  # Loop through the list of div elements\n  for question in question_list:\n    # Get the title of the question\n    question_title = question.find('a', class_ = 'question-hyperlink').text\n\n    # Get the tags of the question\n    tags = []\n    for tag in question.find_all('a', class_ = 'post-tag'):\n      tags.append(tag.text)\n\n    # Get the username of the person who asked the question\n    user_name = question.find('div', class_ = 'user-details').find_next('a').text\n\n    # Get the number of votes for the question\n    votes = question.find('span', class_ = 'vote-count-post').text\n\n    # Get the number of answers for the question\n    answers = question.find('div', class_ = 'status').find_next('strong').text\n\n    # Get the number of views for the question\n    views = question.find('div', class_ = 'views').find_next('div').text.strip()\n\n    # Get the timestamp of when the question was asked\n    timestamp = question.find('div', class_ = 'user-action-time').find_next('span', class_ = 'relativetime').text\n\n    # Create a dictionary with the question data\n    question_data = {\n      'question_title': question_title,\n      'tags': tags,\n      'user_name': user_name,\n      'votes': votes,\n      'answers': answers,\n      'views': views,\n      'timestamp': timestamp\n    }\n\n    # Add the question data to the list\n    questions.append(question_data)\n\n  # Check if the list is not empty\n  if questions:\n    # Convert the list to JSON format\n    json_output = json.dumps(questions)\n\n    # Return the JSON data\n    return json_output\n\n  # If the list is empty, print an error message\n  else:\n    print(\"No data was scraped. Check if you are scraping correctly.\")\n\n# Main function to call the scraper function and pass in the URL\nif __name__ == '__main__':\n  url = 'https://math.stackexchange.com/questions'\n  print(scraper(url))",
    "test_count": 20,
    "test_succ_count": 2
}